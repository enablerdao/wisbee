# Ollama全モデルベンチマーク結果

## パフォーマンステスト結果 (tokens/second)

| モデル | トークン数 | 処理時間(秒) | tok/s |
|--------|------------|--------------|-------|
| **llama3.2:1b** | 281 | 5.17 | **54.31** |
| **qwen3:1.7b** | 896 | 17.21 | **52.05** |
| phi3:mini | 549 | 18.81 | 29.18 |
| jaahas/qwen3-abliterated:0.6b | 464 | 17.69 | 26.23 |
| gemma3:1b | 994 | 47.22 | 21.04 |
| llava:7b | 361 | 19.97 | 18.07 |
| qwen3:latest | 877 | 80.58 | 10.88 |
| gemma3:4b | 761 | 120.25 | 6.32 |

### パフォーマンスランキング
1. **llama3.2:1b** - 54.31 tok/s (最速)
2. **qwen3:1.7b** - 52.05 tok/s
3. phi3:mini - 29.18 tok/s

## Q&A評価結果サマリー

15問の日本語質問に対する各モデルの平均トークン生成数：

| モデル | 平均トークン数 |
|--------|----------------|
| qwen3:1.7b | 81.5 |
| llama3.2:1b | 9.7 |
| llava:7b | 8.0 |
| phi3:mini | 6.7 |

### 特徴
- **qwen3:1.7b**: 最も詳細な回答を生成（平均81.5トークン）
- **llama3.2:1b**: パフォーマンスと回答のバランスが良い
- **phi3:mini**: 簡潔な回答傾向
- **llava:7b**: マルチモーダルモデル（画像対応）

## 推奨モデル

### 速度重視
- **llama3.2:1b** - 最高速で動作

### 日本語品質重視
- **qwen3:1.7b** - 詳細な日本語回答

### バランス型
- **phi3:mini** - 中速で簡潔な回答

### マルチモーダル
- **llava:7b** - 画像入力対応

## ログファイル
- パフォーマンステスト: 実行時の標準出力
- Q&A評価: `/Users/yuki/oeval_logs/oeval_20250607_120729.jsonl`