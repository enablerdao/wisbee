# Ollama モデルベンチマーク総合結果

## 実行日: 2025年6月6日

### 📊 テスト概要

1. **基本性能テスト** - 単純な質問への応答速度と正確性
2. **高度な問題テスト** - フィボナッチ数列、素数判定、コード生成
3. **会話継続性テスト** - 文脈維持能力の評価

### 🏆 モデル別総合評価

#### gemma3:4b
- **基本性能**: 1/3正解（33%）- 日本語理解は良好
- **高度な問題**: 3/3正解（100%）- 優秀な問題解決能力
- **応答速度**: 平均3-4秒/質問
- **総合評価**: ⭐⭐⭐⭐ 最も安定したパフォーマンス

#### qwen3:latest
- **基本性能**: 1/3正解（33%）
- **高度な問題**: 1/3正解（33%）
- **問題点**: `<think>`タグを出力する癖がある
- **応答速度**: 平均7-15秒/質問
- **総合評価**: ⭐⭐ 改善の余地あり

#### llava:7b
- **基本性能**: テスト中
- **応答速度**: 遅い（20秒以上）
- **総合評価**: ⭐ 画像処理向けモデル

#### jaahas/qwen3-abliterated:0.6b
- **基本性能**: 0/3正解（0%）
- **問題点**: 不完全な応答、`<think>`タグ出力
- **応答速度**: 高速（小型モデル）
- **総合評価**: ⭐ 精度に課題

#### llama3.2:1b
- **会話テスト**: 基本的な応答は可能
- **応答速度**: 高速
- **総合評価**: ⭐⭐ 軽量用途向け

#### phi3:mini
- **新規追加モデル**: 詳細テスト未実施
- **期待**: 軽量で高速な応答

### 💡 推奨事項

1. **一般用途**: gemma3:4b
   - 最もバランスが良い
   - 日本語理解力が高い
   - 複雑な問題にも対応可能

2. **高速処理**: llama3.2:1b または phi3:mini
   - 応答速度重視の場合
   - 精度は劣るが実用的

3. **改善が必要なモデル**:
   - qwen3:latest - プロンプト調整で改善可能
   - jaahas/qwen3-abliterated:0.6b - より大きなモデルへの変更を推奨

### 🔧 最適な設定

```json
{
  "temperature": 0.1-0.3,
  "num_predict": 50-100,
  "stream": false
}
```

### 📝 注意事項

- 97は素数です（テストの判定ロジックに誤りがありました）
- タイムアウトは40秒に設定していますが、多くのモデルは10秒以内に応答
- 会話の文脈維持には課題があり、簡潔なプロンプトが効果的