# Ollama モデルベンチマーク 最終結果
実行日: 2025年6月6日

## 🏆 総合ランキング

### 🥇 gemma3:4b - 総合最優秀
- 高度な問題: 3/3 正解（フィボナッチ、コード生成完璧）
- 応答速度: 3-5秒（実用的）
- 日本語理解: 優秀
- 推論能力: 説明付きで正確
- 実用性: 高い

### 🥈 phi3:mini - バランス型
- 応答速度: 高速
- 基本タスク: 良好
- 軽量で実用的

### 🥉 llama3.2:1b - 高速軽量
- 応答速度: 最速クラス
- 基本的な応答: 可能
- リソース消費: 最小

### 📌 その他のモデル
- **qwen3:latest**: `<think>`タグ出力あり（無視すれば使用可）
- **llava:7b**: 画像処理向け（テキストのみでは低速）
- **jaahas/qwen3-abliterated:0.6b**: 最軽量だが精度低い

## 📊 用途別推奨

### 高精度タスク（コーディング、論理問題）
→ **gemma3:4b**

### リアルタイム応答（チャットボット等）
→ **phi3:mini** または **llama3.2:1b**

### リソース制限環境
→ **llama3.2:1b**

### マルチモーダル（画像+テキスト）
→ **llava:7b**

## 🔧 推奨設定
```bash
{
  "model": "gemma3:4b",
  "temperature": 0.1-0.3,  # 事実系
  "temperature": 0.5-0.7,  # 創造系
  "num_predict": 50-100,
  "stream": false
}
```

## 📝 重要な発見
1. gemma3:4bは97を素数でないと誤判定（実際は素数）
2. qwen系モデルは`<think>`タグを出力する傾向
3. 小型モデル（1B以下）は速度優先の用途に最適
4. 会話の文脈維持は全モデルで課題あり

---
テスト実施: 8種類の包括的ベンチマーク
総テスト時間: 約15分
評価モデル数: 6モデル