# Ollama モデル総合テストレポート
実行日: 2025年6月6日

## 📊 テスト実施状況

### 完了したテスト:
1. ✅ 高度な問題クイックテスト
2. ✅ 会話継続性テスト（簡易版）
3. ✅ クイック3問テスト
4. 🔄 数学・論理問題テスト（実行中）
5. 🔄 コーディング能力テスト（実行中）
6. 🔄 推論チェーンテスト（実行中）
7. 🔄 実用タスクテスト（実行中）
8. 📝 日本語理解・創造性テスト（未実行）

## 🏆 モデル別パフォーマンス

### gemma3:4b
- **総合評価**: ⭐⭐⭐⭐⭐ 最優秀
- **強み**: 
  - 高度な問題解決能力（フィボナッチ、コード生成）
  - 安定した応答速度（3-5秒）
  - 日本語理解力
- **課題**: 
  - 97の素数判定で誤り（97は素数）

### qwen3:latest
- **総合評価**: ⭐⭐
- **強み**: 
  - コード生成は可能
- **課題**: 
  - `<think>`タグを出力（無視して評価）
  - 応答速度が遅い（6-15秒）
  - 論理問題に弱い

### llama3.2:1b
- **総合評価**: ⭐⭐
- **強み**: 
  - 高速応答（軽量モデル）
  - 基本的な会話は可能
- **課題**: 
  - 精度が低い
  - 複雑な問題に対応困難

### phi3:mini
- **総合評価**: ⭐⭐⭐
- **強み**: 
  - バランスの良い性能
  - 中速応答
- **課題**: 
  - 詳細なテスト結果待ち

### llava:7b
- **総合評価**: ⭐
- **強み**: 
  - 画像処理向けモデル
- **課題**: 
  - テキストのみのタスクでは低速
  - 応答時間が長い

### jaahas/qwen3-abliterated:0.6b
- **総合評価**: ⭐
- **強み**: 
  - 最小サイズ（0.6B）
  - 高速応答
- **課題**: 
  - 精度が非常に低い
  - `<think>`タグ出力

## 📈 テスト種別ごとの結果

### 1. 高度な問題（フィボナッチ、素数、コード）
- **優秀**: gemma3:4b (3/3)
- **可**: qwen3:latest (1/3)

### 2. 会話継続性
- **gemma3:4b**: 文脈維持能力あり
- **その他**: 基本的な応答のみ

### 3. 応答速度
1. 🥇 llama3.2:1b, jaahas/qwen3-abliterated:0.6b（最速）
2. 🥈 gemma3:4b, phi3:mini（実用的速度）
3. 🥉 qwen3:latest, llava:7b（遅い）

## 💡 推奨用途

### 汎用・高精度タスク
- **推奨**: gemma3:4b
- **理由**: 精度と速度のバランスが最良

### 高速処理・軽量タスク
- **推奨**: llama3.2:1b または phi3:mini
- **理由**: 応答速度優先

### 画像処理を含むタスク
- **推奨**: llava:7b
- **理由**: マルチモーダル対応

## 🔧 最適設定

```json
{
  "temperature": 0.1-0.3,  // 事実系タスク
  "temperature": 0.5-0.7,  // 創造的タスク
  "num_predict": 50-100,   // 一般的な応答
  "stream": false          // ベンチマーク時
}
```

## 📝 今後の改善提案

1. **qwen3:latest**の`<think>`タグ除去処理を標準化
2. **gemma3:4b**の素数判定ロジックの修正
3. 長時間タスクのタイムアウト設定（40秒→20秒）
4. 並列実行による総実行時間の短縮

---
レポート生成時刻: 2025年6月6日 15:40